{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW model in Sci-kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 1 1 1]\n",
      " [0 1 1 1 1 0 0 1 1 0 1 1 0 0 1 1 0 0 0 0]]\n",
      "{'you': 19, 'and': 0, 'would': 18, 'have': 6, 'understood': 17, 'that': 16, 'sentence': 13, 'in': 7, 'fraction': 5, 'of': 9, 'second': 12, 'but': 1, 'machines': 8, 'simply': 14, 'cannot': 2, 'process': 10, 'text': 15, 'data': 3, 'raw': 11, 'form': 4}\n",
      "['and' 'but' 'cannot' 'data' 'form' 'fraction' 'have' 'in' 'machines' 'of'\n",
      " 'process' 'raw' 'second' 'sentence' 'simply' 'text' 'that' 'understood'\n",
      " 'would' 'you']\n",
      "      and  but  cannot  data  form  fraction  have  in  machines  of  process  \\\n",
      "Doc0    1    0       0     0     0         1     1   1         0   1        0   \n",
      "Doc1    0    1       1     1     1         0     0   1         1   0        1   \n",
      "\n",
      "      raw  second  sentence  simply  text  that  understood  would  you  \n",
      "Doc0    0       1         1       0     0     1           1      1    1  \n",
      "Doc1    1       0         0       1     1     0           0      0    0  \n"
     ]
    }
   ],
   "source": [
    "corpus = ['You and I would have understood that sentence in a fraction of a second.', \n",
    "          'But machines simply cannot process text data in raw form.']\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    lowercase = True,\n",
    "    tokenizer=None,\n",
    "    stop_words = None,\n",
    "    preprocessor=None,\n",
    "    max_features = 5000\n",
    ")\n",
    "# convert the documents into a document-term matrix\n",
    "wm = vectorizer.fit_transform(corpus)\n",
    "print(wm.todense()) \n",
    "#shape of count vector: 2 docs and 20 unique words (columns)!\n",
    "wm.shape\n",
    "# show resulting vocabulary; the numbers are not counts, they are the position in the sparse vector\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "print(vocabulary)\n",
    "\n",
    "tokens = vectorizer.get_feature_names_out()\n",
    "print(tokens)\n",
    "\n",
    "doc_name = ['Doc{:d}'.format(i) for i, _ in enumerate(wm)]\n",
    "df = pd.DataFrame(data=wm.toarray(), columns=tokens, index=doc_name)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency\n",
    "For term frequency in a document tf(t,d), the simplest choice is to use the raw count of a term in a document,\n",
    "### tf(t,d)=log(1+ft,d)\n",
    "\n",
    "# Inverse Document Frequency\n",
    "The inverse-document frequency is a measure of how much information the word provides, i.e., if it is a common or rare across all the documents. It determines the weight of rare words across all documents in the corpus.\n",
    "### idf(t,D)=log(N∣{d∈D:t∈d}∣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 16)\n",
      "['ate' 'away' 'cat' 'end' 'finally' 'from' 'had' 'house' 'little' 'mouse'\n",
      " 'of' 'ran' 'saw' 'story' 'the' 'tiny']\n",
      "[[0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 1 0 2 0]\n",
      " [0 1 0 0 0 1 0 1 0 1 0 1 0 0 2 0]\n",
      " [1 0 1 0 1 0 0 0 0 1 0 0 0 0 2 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 1 0 0 1 2 0]]\n",
      "      ate  away  cat  end  finally  from  had  house  little  mouse  of  ran  \\\n",
      "Doc0    0     0    0    0        0     0    1      1       1      1   0    0   \n",
      "Doc1    0     0    1    0        0     0    0      0       0      1   0    0   \n",
      "Doc2    0     1    0    0        0     1    0      1       0      1   0    1   \n",
      "Doc3    1     0    1    0        1     0    0      0       0      1   0    0   \n",
      "Doc4    0     0    0    1        0     0    0      0       0      1   1    0   \n",
      "\n",
      "      saw  story  the  tiny  \n",
      "Doc0    0      0    1     1  \n",
      "Doc1    1      0    2     0  \n",
      "Doc2    0      0    2     0  \n",
      "Doc3    0      0    2     0  \n",
      "Doc4    0      1    2     0  \n"
     ]
    }
   ],
   "source": [
    "doc = [\n",
    "    \"the house had a tiny little mouse\",\n",
    "    \"the cat saw the mouse\",\n",
    "    \"the mouse ran away from the house\",\n",
    "    \"the cat finally ate the mouse\",\n",
    "    \"the end of the mouse story\"\n",
    "]\n",
    "\n",
    "#instantiate CountVectorizer()\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# generates word counts for the words in doc\n",
    "word_count_vector = cv.fit_transform(doc)\n",
    "print(word_count_vector.shape) # doc has 5 rowa and 16 column (16 unique words)\n",
    "\n",
    "tokens = cv.get_feature_names_out()\n",
    "print(tokens)\n",
    "\n",
    "# tearm document matrix\n",
    "print(word_count_vector.toarray())\n",
    "#create data frame\n",
    "doc_names = [\"Doc{:d}\".format(i) for i, _ in enumerate(word_count_vector)]\n",
    "df = pd.DataFrame(data=word_count_vector.toarray(), index=doc_names, columns=tokens)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         idf_weights\n",
      "ate         2.098612\n",
      "away        2.098612\n",
      "cat         1.693147\n",
      "end         2.098612\n",
      "finally     2.098612\n",
      "from        2.098612\n",
      "had         2.098612\n",
      "house       1.693147\n",
      "little      2.098612\n",
      "mouse       1.000000\n",
      "of          2.098612\n",
      "ran         2.098612\n",
      "saw         2.098612\n",
      "story       2.098612\n",
      "the         1.000000\n",
      "tiny        2.098612\n"
     ]
    }
   ],
   "source": [
    "Tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "Tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "#print idf values\n",
    "df_idf = pd.DataFrame(Tfidf_transformer.idf_, index=tokens, columns=[\"idf_weights\"])\n",
    "print(df_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>0.493562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>0.493562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny</th>\n",
       "      <td>0.493562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>0.398203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <td>0.235185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.235185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ate</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>away</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ran</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tf-idf\n",
       "had      0.493562\n",
       "little   0.493562\n",
       "tiny     0.493562\n",
       "house    0.398203\n",
       "mouse    0.235185\n",
       "the      0.235185\n",
       "ate      0.000000\n",
       "away     0.000000\n",
       "cat      0.000000\n",
       "end      0.000000\n",
       "finally  0.000000\n",
       "from     0.000000\n",
       "of       0.000000\n",
       "ran      0.000000\n",
       "saw      0.000000\n",
       "story    0.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count matrix\n",
    "count_vector=cv.transform(doc)\n",
    "# tf-idf scores\n",
    "tf_idf_vector=Tfidf_transformer.transform(count_vector)\n",
    "\n",
    "#get tfidf vector for first document\n",
    "first_document_vector=tf_idf_vector[0]\n",
    " \n",
    "#print the scores\n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=tokens, columns=[\"tf-idf\"])\n",
    "df.sort_values(by=[\"tf-idf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refrence:- https://mmuratarat.github.io/2020-04-03/bow_model_tf_idf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
